{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f871a58d",
   "metadata": {},
   "source": [
    "0.1 utils, all helpful method including validate local path, local logging, serialise and deserialise json file, read and write files, create and delet path, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1533a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b16dbc7c",
   "metadata": {},
   "source": [
    "0.2 model class, including loading with name method, train with dataloaders method, and evaluate (on test of course) method (since we only work with single modality and the input is always a combination two texts, and the output is always a text, we can share the same class all over the project, and we will overide in case we need more feature) (with loaded data train and stop in val and monitor via w&b, do not pass model parameter to w&b, keep them in local dir checkpoints with peroper naming and also keep a log in the dir logs. and create a json file with proper name of task in the working dir given the match betwen the run folder path under checkpoints and the run log path.) (the checkpoint resume from latest feature should have, wo do not want to train repeatedly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7438fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b776ad8b",
   "metadata": {},
   "source": [
    "0.3 plot evaluation result class, including all method we need to plot a conference level paper plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67993775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc4788cc",
   "metadata": {},
   "source": [
    "0.4 define all configurable hyper parameters, and provice grid search method keep a local json called grid-search-record.json save the past running results, each time we run the whole note book, if we enable grid search, have to read the json file, and continue next grid search values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43883a74",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c73327ca",
   "metadata": {},
   "source": [
    "1.1 load model via transformers, we pick Qwen3-0.6B and Qwen3-4B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a43700f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "142b504e",
   "metadata": {},
   "source": [
    "1.2 load custom data from local datasets dir, the data with 3 types of data, \n",
    "\n",
    "- x : current frame in ascii art, \n",
    "- y: current action token, \n",
    "- z: next frame ascii art, \n",
    "\n",
    "all in plain text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c7bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac3e0933",
   "metadata": {},
   "source": [
    "1.3 split loaded data to all, train, val and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6280e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f4f2bbb",
   "metadata": {},
   "source": [
    "2.1 evaluate both model on all data, for next frame reconstraction task, input x and y, output z, save result to 2.1-result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb67ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b314d905",
   "metadata": {},
   "source": [
    "2.2 plot the result of the evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcffcde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fbfbfb4",
   "metadata": {},
   "source": [
    "2.3 evaluate both model on all data for the action recognition task, input x and z, output y, save result to 2.3-result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09895268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86ca3c70",
   "metadata": {},
   "source": [
    "2.4 plot the result of the evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80857f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f26871a2",
   "metadata": {},
   "source": [
    "3.1 fine tune both model with lora method, task is next frame reconstraction, input x and y, output z, with loaded data train and stop in val and monitor via w&b, do not pass model parameter to w&b, keep them in local dir checkpoints with peroper naming and also keep a log in the dir logs. and create 3.1-training-metadata.json file in the working dir given the match betwen the run folder path under checkpoints and the run log path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c5b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f1bd6cc",
   "metadata": {},
   "source": [
    "3.2 evaluate on test dataset, and save to 3.2-result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5ae36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e86f2a8e",
   "metadata": {},
   "source": [
    "3.3 plot the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7398c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dba795fd",
   "metadata": {},
   "source": [
    "4.1 do finetuning with lora with both model, perform action recognition task, input x and z, output y, and monitor via w&b, do not pass model parameter to w&b, keep them in local dir checkpoints with peroper naming and also keep a log in the dir logs. and create a 4.2-training-metadata.json file in the working dir given the match betwen the run folder path under checkpoints and the run log path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6e959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b1b8288",
   "metadata": {},
   "source": [
    "4.3 evaluate the online rl result and save to 4.3-result.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc34b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84502e15",
   "metadata": {},
   "source": [
    "4.4 plot the evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce88003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
